import mlflow
import mlflow.spark
from pyspark.sql import SparkSession
from pyspark.sql.functions import when
from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler
from pyspark.ml.classification import NaiveBayes
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder

# Spark ì„¸ì…˜
spark = SparkSession.builder.appName("WineNB_Tuning").getOrCreate()

# CSV ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
data = spark.read.csv("wine_quality_merged.csv", header=True, inferSchema=True)

# ì‹¤í—˜ ì´ë¦„ ì„¤ì •
mlflow.set_experiment("WineQualityExperiment")

# ë¼ë²¨ ì¬ë¶„ë¥˜: 3~5=0, 6~9=1
data = data.withColumn("label_class", when(data.quality <= 5, 0).otherwise(1))

# type ì»¬ëŸ¼ one-hot encoding
if "type" in data.columns:
    type_indexer = StringIndexer(inputCol="type", outputCol="type_index")
    data = type_indexer.fit(data).transform(data)
    encoder = OneHotEncoder(inputCols=["type_index"], outputCols=["type_vec"])
    data = encoder.fit(data).transform(data)
    feature_cols = [c for c in data.columns if c not in ("quality", "type", "label_class")] + ["type_vec"]
else:
    feature_cols = [c for c in data.columns if c not in ("quality", "label_class")]

# íŠ¹ì§• ë²¡í„°í™”
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features_raw")
data = assembler.transform(data)

# ìˆ˜ì¹˜í˜• ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler(inputCol="features_raw", outputCol="features")
scaler_model = scaler.fit(data)
data = scaler_model.transform(data)

# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
train_ratio = 0.8
test_ratio = 0.2
train, test = data.randomSplit([train_ratio, test_ratio], seed=42)

# MLflow ì‹¤í—˜ ì‹¤í–‰
with mlflow.start_run(run_name="NB_Wine_Quality_Tuning"):
    mlflow.log_param("num_features", len(feature_cols))
    mlflow.log_param("train_ratio", train_ratio)
    mlflow.log_param("test_ratio", test_ratio)
    mlflow.log_param("model_type", "NaiveBayes")

    # ğŸ”¹ Naive Bayes ëª¨ë¸ ì •ì˜
    nb = NaiveBayes(featuresCol="features", labelCol="label_class", smoothing=1.0)

    # ğŸ”¹ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ (smoothing íŒŒë¼ë¯¸í„°)
    paramGrid = (ParamGridBuilder()
                 .addGrid(nb.smoothing, [0.5, 1.0, 2.0])
                 .build())

    # ğŸ”¹ Cross-validation
    evaluator = MulticlassClassificationEvaluator(labelCol="label_class", predictionCol="prediction", metricName="accuracy")
    cv = CrossValidator(estimator=nb, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=3)

    # í•™ìŠµ
    cv_model = cv.fit(train)

    # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ
    best_model = cv_model.bestModel
    best_params = {
        "smoothing": best_model.getOrDefault("smoothing")
    }
    mlflow.log_params(best_params)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
    predictions = best_model.transform(test)

    # í‰ê°€
    accuracy = evaluator.setMetricName("accuracy").evaluate(predictions)
    f1_evaluator = MulticlassClassificationEvaluator(labelCol="label_class", predictionCol="prediction", metricName="f1")
    f1 = f1_evaluator.evaluate(predictions)

    print("Best Params:", best_params)
    print("Accuracy:", accuracy)
    print("F1-score:", f1)

    # MLflowì— ê¸°ë¡
    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("f1_score", f1)

    # ëª¨ë¸ ì €ì¥
    mlflow.spark.log_model(best_model, "naive_bayes_model")
